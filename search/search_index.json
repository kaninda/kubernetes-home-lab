{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Kubernetes Home Lab","text":"<p>Welcome \ud83d\udc4b</p> <p>This site documents the design and installation of a bare-metal Kubernetes cluster built at home using kubeadm.</p> <p>The goal of this project is to: - learn Kubernetes internals - build a realistic bare-metal cluster - document every step for reproducibility</p> <p>Start with the Overview section to understand the cluster design and scope.</p> <p></p>"},{"location":"cni-calico/","title":"CNI Installation (Calico)","text":"<p>This section describes how to install Calico as the Container Network Interface (CNI) for the Kubernetes Home Lab.</p> <p>Calico is responsible for: - Pod-to-Pod networking across nodes - Pod IP address allocation - Network routing and encapsulation - Network policy enforcement (optional, later)</p>"},{"location":"cni-calico/#prerequisites","title":"Prerequisites","text":"<p>Before installing Calico, ensure that:</p> <ul> <li>the Kubernetes control plane is initialized</li> <li>kubectl access is configured</li> <li>all nodes are in NotReady state (expected before CNI installation)</li> </ul>"},{"location":"cni-calico/#verify-current-node-status","title":"Verify current node status:","text":"<pre><code>kubectl get nodes\n</code></pre> <p>Expected output:</p> <ul> <li>Control plane node is present</li> <li>Status is NotReady</li> </ul>"},{"location":"cni-calico/#network-design-assumptions","title":"Network design assumptions","text":"<p>This lab uses the following network ranges:</p> Network type CIDR Home LAN 192.168.1.0/24 Pod Network 10.244.0.0/16"},{"location":"cni-calico/#the-pod-network-cidr-must-match-the-value-provided-during-kubeadm-init","title":"\u26a0\ufe0f The Pod Network CIDR must match the value provided during kubeadm init.","text":""},{"location":"cni-calico/#why-calico","title":"Why Calico","text":"<p>Calico was selected for this home lab because it provides:</p> <ul> <li>Native Kubernetes networking (no overlay requirement)</li> <li>High performance and low overhead</li> <li>Optional encapsulation (IP-in-IP or VXLAN)</li> <li>First-class support for NetworkPolicies</li> <li>Production-grade behavior while remaining simple to operate</li> </ul>"},{"location":"cni-calico/#logical-pod-network-topology-calico","title":"Logical Pod Network topology (Calico)","text":"<p>This diagram represents the logical networking model once Calico is installed.</p> <ul> <li>Each node is assigned a Pod CIDR</li> <li>Pods receive IPs from the Pod Network range</li> <li>Calico routes Pod traffic between nodes</li> <li>No NAT is required between Pods</li> </ul> <p></p>"},{"location":"cni-calico/#install-calico","title":"Install Calico","text":"<p>Calico is installed by applying the official manifest.</p>"},{"location":"cni-calico/#download-the-calico-manifest","title":"Download the Calico manifest","text":"<pre><code>curl -O https://raw.githubusercontent.com/projectcalico/calico/v3.27.3/manifests/calico.yaml\n</code></pre>"},{"location":"cni-calico/#_1","title":"CNI (Calico)","text":"<p>(Optional) Review the manifest:</p> <pre><code>less calico.yaml\n</code></pre>"},{"location":"cni-calico/#apply-the-manifest","title":"Apply the manifest","text":"<pre><code>kubectl apply -f calico.yaml\n</code></pre> <p>This will deploy:</p> <ul> <li>calico-node (DaemonSet)</li> <li>calico-kube-controllers</li> <li>required CRDs and RBAC rules</li> </ul>"},{"location":"cni-calico/#verify-calico-deployment","title":"Verify Calico deployment","text":""},{"location":"cni-calico/#check-calico-pods","title":"Check Calico pods:","text":"<pre><code>kubectl get pods -n kube-system\n</code></pre>"},{"location":"cni-calico/#expected-output","title":"Expected output:","text":"<ul> <li>calico-node pods running on all nodes</li> <li>calico-kube-controllers running</li> </ul>"},{"location":"cni-calico/#example","title":"Example:","text":"<pre><code>calico-node-xxxxx            Running\ncalico-kube-controllers      Running\n</code></pre>"},{"location":"cni-calico/#verify-node-readiness","title":"Verify node readiness","text":"<p>Once Calico is running, nodes should transition to Ready.</p> <pre><code>kubectl get nodes\n</code></pre> <p>Expected output:</p> <ul> <li>control plane node is Ready</li> </ul>"},{"location":"cni-calico/#verify-pod-networking","title":"Verify Pod networking","text":""},{"location":"cni-calico/#deploy-a-simple-test-pod","title":"Deploy a simple test Pod:","text":"<pre><code>kubectl run test-pod --image=busybox --restart=Never -- sleep 3600\n</code></pre>"},{"location":"cni-calico/#verify-pod-status","title":"Verify Pod status:","text":"<pre><code>kubectl get pods\n</code></pre>"},{"location":"cni-calico/#expected","title":"Expected:","text":"<ul> <li>Pod is Running</li> </ul>"},{"location":"cni-calico/#optional-check-pod-ip","title":"(Optional) Check Pod IP:","text":"<pre><code>kubectl get pod test-pod -o wide\n</code></pre>"},{"location":"cni-calico/#cleanup-test-pod","title":"Cleanup test Pod","text":"<pre><code>kubectl delete pod test-pod\n</code></pre>"},{"location":"cni-calico/#result","title":"Result","text":"<p>At this stage:</p> <ul> <li>Calico is installed and operational</li> <li>Pod networking is functional</li> <li>The cluster is ready to accept worker nodes</li> </ul>"},{"location":"hardware/","title":"Hardware","text":"<p>This section describes the physical hardware used to build the Kubernetes Home Lab.</p> <p>The goal is to use compact, power-efficient, and affordable machines while keeping a setup close to a real-world bare-metal Kubernetes cluster.</p>"},{"location":"hardware/#hardware-overview","title":"Hardware overview","text":"Node Role CPU RAM Storage Network cp-1 Control Plane Ryzen 5 3500U 16GB 512GB SSD 2.5 GbE worker-1 Worker Node Ryzen 5 5500U 32GB 500GB SSD 2.5 GbE worker-2 Worker Node Ryzen 5 5500U 32GB 500GB SSD 2.5 GbE"},{"location":"hardware/#control-plane-node","title":"Control Plane node","text":"<p>The control plane is hosted on a dedicated mini-PC.</p> <p>Characteristics: - Sufficient CPU power for API server, scheduler and controller manager - Moderate memory footprint (16 GB is sufficient for a single control plane) - SSD storage for etcd and system components - Dedicated Ethernet interface</p> <p>This node is intentionally not used for application workloads.</p>"},{"location":"hardware/#worker-nodes","title":"Worker nodes","text":"<p>Worker nodes are more powerful and designed to run application workloads.</p> <p>Characteristics: - Higher CPU core count for parallel workloads - More memory for pods and caches - Fast local SSD storage - Wired Ethernet connectivity</p> <p>This allows realistic scheduling, resource limits and scaling experiments.</p>"},{"location":"hardware/#networking-hardware","title":"Networking hardware","text":"<p>All nodes are connected using a dedicated 2.5 GbE Ethernet switch.</p> <p>Design choices: - Wired network only (no Wi-Fi) - Predictable latency and throughput - No network bottlenecks between nodes</p>"},{"location":"hardware/#key-hardware-design-decisions","title":"Key hardware design decisions","text":"<ul> <li>Single control plane (home lab scope)</li> <li>Dedicated nodes (no virtualization)</li> <li>Wired Ethernet only</li> <li>Over-provisioned worker nodes</li> <li>Energy-efficient hardware</li> </ul>"},{"location":"kubernetes-install/","title":"Kubernetes Installation (kubeadm - v1.34)","text":"<p>This section describes how to install Kubernetes components and initialize the cluster using kubeadm.</p> <p>At the end of this section, a single-node control plane will be up and running, ready to accept worker nodes.</p>"},{"location":"kubernetes-install/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, ensure that: - the operating system is prepared (see OS Preparation) - swap is disabled - containerd is running - required kernel modules and sysctl parameters are applied</p> <p>All commands below must be executed as root or with sudo.</p>"},{"location":"kubernetes-install/#install-kubernetes-packages","title":"Install Kubernetes packages","text":""},{"location":"kubernetes-install/#add-kubernetes-apt-repository-v134","title":"Add Kubernetes APT repository (v1.34)","text":"<p>Install required packages</p> <pre><code>sudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl gpg\n</code></pre> <p>Create keyrings directory (if not present)</p> <pre><code>sudo mkdir -p -m 755 /etc/apt/keyrings\n</code></pre> <p>Add CPG key</p> <pre><code>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.34/deb/Release.key \\\n| sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n</code></pre> <p>Add Kubernetes APT repository</p> <pre><code>echo \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] \\\nhttps://pkgs.k8s.io/core:/stable:/v1.34/deb/ /\" \\\n| sudo tee /etc/apt/sources.list.d/kubernetes.list\n</code></pre> <p>Update package index</p> <pre><code>sudo apt-get update\n</code></pre>"},{"location":"kubernetes-install/#install-kubernetes-components-pinned-version","title":"Install Kubernetes components (pinned version)","text":"<p>Select the Kubernetes version to install:</p> <pre><code>apt-cache madison kubeadm\n</code></pre> <p>Expected output:</p> <pre><code>kubeadm | 1.34.3-1.1 | https://pkgs.k8s.io/core:/stable:/v1.34/deb  Packages\nkubeadm | 1.34.2-1.1 | https://pkgs.k8s.io/core:/stable:/v1.34/deb  Packages\nkubeadm | 1.34.1-1.1 | https://pkgs.k8s.io/core:/stable:/v1.34/deb  Packages\nkubeadm | 1.34.0-1.1 | https://pkgs.k8s.io/core:/stable:/v1.34/deb  Packages\n</code></pre> <p>Install kubeadm, kubelet and kubectl using the selected version (example: 1.34.3-1.1):</p> <pre><code>sudo apt-get install -y \\\nkubelet=1.34.3-1.1 \\\nkubeadm=1.34.3-1.1 \\\nkubectl=1.34.3-1.1\n</code></pre> <p>Hold package versions</p> <p>Prevent automatic upgrades to avoid version drift:</p> <pre><code>sudo apt-mark hold kubelet kubeadm kubectl\n</code></pre>"},{"location":"kubernetes-install/#verify-installation","title":"Verify installation","text":"<pre><code>kubeadm version\nkubectl version --client\nkubelet --version\n</code></pre> <p>Expected output: - all components report v1.34.x</p>"},{"location":"kubernetes-install/#configure-kubelet","title":"Configure kubelet","text":"<p>Ensure kubelet uses the systemd cgroup driver, matching containerd. This is already handled by containerd configuration, but kubelet must be restarted:</p> <pre><code>sudo systemctl daemon-reexec\nsudo systemctl restart kubelet\n</code></pre> <p>At this point, kubelet will fail to start until the cluster is initialized. This is expected behavior.</p>"},{"location":"kubernetes-install/#initialize-the-control-plane","title":"Initialize the control plane","text":"<p>Run the following command on the control plane node only:</p> <pre><code>sudo kubeadm init \\\n--apiserver-advertise-address=192.168.1.53 \\\n--pod-network-cidr=10.244.0.0/16\n</code></pre> <p>The Pod CIDR must match the CNI configuration that will be installed later.</p>"},{"location":"kubernetes-install/#save-the-join-command","title":"Save the join command","text":"<p>At the end of the output, kubeadm prints a kubeadm join command.</p> <p>\u26a0\ufe0f Save this command \u2014 it will be required to join worker nodes later.</p>"},{"location":"kubernetes-install/#configure-kubectl-access","title":"Configure kubectl access","text":"<p>Configure kubectl for the current user:</p> <pre><code>mkdir -p $HOME/.kube\nsudo cp /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n</code></pre> <p>Verify access:</p> <pre><code>kubectl get nodes\n</code></pre>"},{"location":"kubernetes-install/#verify-control-plane-status","title":"Verify control plane status","text":"<p>Check core components:</p> <pre><code>kubectl get pods -n kube-system\n</code></pre> <p>Expected state:</p> <ul> <li>kube-apiserver running</li> <li>kube-controller-manager running</li> <li>kube-scheduler running</li> <li>etcd running</li> </ul> <p>Some pods may be in Pending state until a CNI is installed \u2014 this is normal.</p>"},{"location":"kubernetes-reset/","title":"Kubernetes Reset (kubeadm)","text":"<p>This section describes how to cleanly reset a Kubernetes cluster installed with kubeadm.</p> <p>A reset may be required in the following situations: - failed or incomplete cluster initialization - incorrect Pod CIDR or network configuration - CNI installation issues - certificate or kubeadm configuration errors - reinstallation from scratch</p> <p>The goal is to return the system to a clean, pre-Kubernetes state without reinstalling the operating system.</p>"},{"location":"kubernetes-reset/#important-warning","title":"\u26a0\ufe0f Important warning","text":"<p>This procedure:</p> <ul> <li>removes all Kubernetes state</li> <li>deletes etcd data</li> <li>removes CNI configuration</li> <li>does not preserve workloads or cluster data</li> </ul> <p>Use it only when you intend to rebuild the cluster.</p>"},{"location":"kubernetes-reset/#reset-the-control-plane-and-worker-nodes","title":"Reset the control plane and worker nodes","text":"<p>The following steps must be executed on all nodes (control plane and workers).</p>"},{"location":"kubernetes-reset/#run-kubeadm-reset","title":"Run kubeadm reset","text":"<pre><code>sudo kubeadm reset --force\n</code></pre> <p>This command:</p> <ul> <li>stops Kubernetes services</li> <li>removes static pod manifests</li> <li>deletes etcd data (on control plane)</li> <li>resets kubeadm state</li> </ul>"},{"location":"kubernetes-reset/#remove-kubernetes-configuration-files","title":"Remove Kubernetes configuration files","text":"<pre><code>rm -rf $HOME/.kube\nsudo rm -rf /etc/kubernetes\n</code></pre>"},{"location":"kubernetes-reset/#cleanup-cni-configuration","title":"Cleanup CNI configuration","text":""},{"location":"kubernetes-reset/#remove-cni-configuration-and-state","title":"Remove CNI configuration and state:","text":"<pre><code>sudo rm -rf /etc/cni/net.d\nsudo rm -rf /var/lib/cni\n</code></pre>"},{"location":"kubernetes-reset/#if-calico-was-used-also-remove-its-state","title":"If Calico was used, also remove its state:","text":"<pre><code>sudo rm -rf /var/lib/calico\n</code></pre>"},{"location":"kubernetes-reset/#cleanup-iptables-rules-recommended","title":"Cleanup iptables rules (recommended)","text":"<p>Kubernetes and CNI plugins modify iptables rules. Reset them to avoid conflicts.</p> <pre><code>sudo iptables -F\nsudo iptables -t nat -F\nsudo iptables -t mangle -F\nsudo iptables -X\n</code></pre>"},{"location":"kubernetes-reset/#restart-container-runtime-and-kubelet","title":"Restart container runtime and kubelet","text":"<pre><code>sudo systemctl restart containerd\nsudo systemctl restart kubelet\n</code></pre>"},{"location":"kubernetes-reset/#verify-system-state","title":"Verify system state","text":""},{"location":"kubernetes-reset/#ensure-kubernetes-is-no-longer-active","title":"Ensure Kubernetes is no longer active:","text":"<pre><code>kubectl get nodes\n</code></pre> <p>Expected:</p> <ul> <li>command fails or reports no configuration</li> </ul> <p>Check that no Kubernetes ports are listening:</p> <pre><code>sudo ss -lntp | grep 6443\n</code></pre> <p>Expected:</p> <ul> <li>no output</li> </ul>"},{"location":"kubernetes-reset/#optional-reboot-the-node","title":"Optional: reboot the node","text":"<p>A reboot ensures:</p> <ul> <li>clean network state</li> <li>cleared virtual interfaces</li> <li>clean kernel routing tables</li> </ul> <pre><code>sudo reboot\n</code></pre>"},{"location":"network-topology/","title":"Network Topology","text":"<p>This section describes the physical and logical network topology of the Kubernetes Home Lab.</p> <p>The goal is to clearly understand: - how nodes are connected at the network level - how Kubernetes components communicate - how Pod networking is handled</p>"},{"location":"network-topology/#high-level-overview","title":"High-level overview","text":"<p>The cluster is deployed on a home LAN with: - a router providing DHCP reservations - a dedicated 2.5 GbE switch - all Kubernetes nodes connected via Ethernet</p> <p>All nodes use static IPs or DHCP reservations to ensure predictable addressing.</p>"},{"location":"network-topology/#physical-network-topology","title":"Physical network topology","text":""},{"location":"network-topology/#_1","title":"Network Topology","text":""},{"location":"network-topology/#kubernetes-control-plane-communication","title":"Kubernetes control plane communication","text":"<ul> <li>The kube-apiserver runs on the control plane node</li> <li>Worker nodes communicate exclusively with the API server</li> <li>All control traffic uses the LAN network</li> </ul>"},{"location":"network-topology/#pod-network-calico","title":"Pod network (Calico)","text":"<p>The cluster uses Calico as the CNI. - Each node is assigned a Pod CIDR - Pods communicate directly across nodes - Pod traffic is encapsulated and routed by Calico - The Pod CIDR does not overlap with the LAN network</p> <p></p>"},{"location":"os-preparation/","title":"OS Preparation (Ubuntu Server)","text":"<p>This section describes all system-level prerequisites required before installing Kubernetes using kubeadm.</p> <p>The goal is to ensure:</p> <ul> <li>system stability</li> <li>Kubernetes compatibility</li> <li>predictable and reproducible behavior across all nodes</li> </ul> <p>All steps below must be applied on every node:</p> <ul> <li>control plane</li> <li>worker nodes</li> </ul>"},{"location":"os-preparation/#base-assumptions","title":"Base assumptions","text":"<ul> <li>OS: Ubuntu Server 22.04 LTS (or newer)</li> <li>Architecture: amd64</li> <li>Network: static IP or DHCP reservation</li> <li>User has sudo privileges</li> </ul>"},{"location":"os-preparation/#disable-swap","title":"Disable swap","text":"<p>Kubernetes requires swap to be disabled. The kubelet will refuse to start if swap is enabled.</p>"},{"location":"os-preparation/#disable-swap-immediately","title":"Disable swap immediately","text":"<pre><code>sudo swapoff -a\n</code></pre>"},{"location":"os-preparation/#disable-swap-permanently","title":"Disable swap permanently","text":"<p>Edit /etc/fstab and comment out any swap entry:</p> <pre><code>sudo sed -i '/ swap / s/^/#/' /etc/fstab\n</code></pre>"},{"location":"os-preparation/#verify-swap-status","title":"Verify swap status","text":"<pre><code>free -h\n</code></pre> <p>Expected output: Swap: 0B</p>"},{"location":"os-preparation/#load-required-kernel-modules","title":"Load required kernel modules","text":"<p>Kubernetes networking requires specific kernel modules.</p>"},{"location":"os-preparation/#configure-modules-to-load-at-boot","title":"Configure modules to load at boot","text":"<pre><code>sudo tee /etc/modules-load.d/k8s.conf &lt;&lt;EOF\noverlay\nbr_netfilter\nEOF\n</code></pre>"},{"location":"os-preparation/#load-modules-immediately","title":"Load modules immediately","text":"<pre><code>sudo modprobe overlay\nsudo modprobe br_netfilter\n</code></pre>"},{"location":"os-preparation/#verify-loaded-modules","title":"Verify loaded modules","text":"<pre><code>lsmod | grep -E 'overlay|br_netfilter'\n</code></pre>"},{"location":"os-preparation/#configure-kernel-parameters-sysctl","title":"Configure kernel parameters (sysctl)","text":"<p>Kubernetes requires proper packet forwarding and bridge traffic handling.</p>"},{"location":"os-preparation/#configure-sysctl-parameters","title":"Configure sysctl parameters","text":"<pre><code>sudo tee /etc/sysctl.d/k8s.conf &lt;&lt;EOF\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.ipv4.ip_forward                = 1\nEOF\n</code></pre>"},{"location":"os-preparation/#apply-settings","title":"Apply settings","text":"<pre><code>sudo sysctl --system\n</code></pre>"},{"location":"os-preparation/#verify-settings","title":"Verify settings","text":"<pre><code>sysctl net.bridge.bridge-nf-call-iptables\nsysctl net.ipv4.ip_forward\n</code></pre> <p>Expected value: 1</p>"},{"location":"os-preparation/#install-container-runtime-containerd","title":"Install container runtime (containerd)","text":"<p>Kubernetes requires a CRI-compatible container runtime. This lab uses containerd.</p>"},{"location":"os-preparation/#install-containerd","title":"Install containerd","text":"<pre><code>sudo apt-get update\nsudo apt-get install -y containerd\n</code></pre>"},{"location":"os-preparation/#configure-containerd","title":"Configure containerd","text":"<pre><code>sudo mkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n</code></pre>"},{"location":"os-preparation/#enable-systemd-cgroup-driver","title":"Enable systemd cgroup driver","text":"<p>Edit /etc/containerd/config.toml and ensure:</p> <pre><code>SystemdCgroup = true\n</code></pre> <p>You can do it automatically:</p> <pre><code>sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml\n</code></pre>"},{"location":"os-preparation/#restart-and-enable-containerd","title":"Restart and enable containerd","text":"<pre><code>sudo systemctl restart containerd\nsudo systemctl enable containerd\n</code></pre>"},{"location":"os-preparation/#verify-containerd-status","title":"Verify containerd status","text":"<pre><code>systemctl status containerd\n</code></pre>"},{"location":"os-preparation/#verify-system-readiness","title":"Verify system readiness","text":"<p>Before moving forward, ensure the following: - swap is disabled - required kernel modules are loaded - sysctl parameters are applied - containerd is running</p> <p>This node is now ready for Kubernetes installation using kubeadm.</p>"},{"location":"os-preparation/#network-ranges","title":"Network ranges","text":"Network type CIDR Home LAN 192.168.1.0/24 Pod Network 10.244.0.0/16"},{"location":"os-preparation/#key-design-decisions","title":"Key design decisions","text":"<ul> <li>Wired Ethernet only for cluster nodes</li> <li>Static addressing for predictability</li> <li>Dedicated Pod CIDR to avoid routing conflicts</li> <li>Single control plane (home lab scope)</li> </ul> <p>This topology provides a simple, stable and production-like foundation for Kubernetes experimentation.</p>"},{"location":"overview/","title":"Overview","text":"<p>This documentation describes the design, setup, and operation of a bare-metal Kubernetes home lab.</p> <p>The cluster is built using kubeadm on Ubuntu Server, with a strong focus on: - clarity - reproducibility - production-like behavior</p> <p>While this is a home lab, all design choices aim to stay as close as possible to real-world Kubernetes environments.</p>"},{"location":"overview/#cluster-goals","title":"Cluster goals","text":"<p>The main goals of this Kubernetes Home Lab are:</p> <ul> <li>Learn Kubernetes fundamentals on bare metal</li> <li>Understand cluster internals and networking</li> <li>Practice installation, upgrades and troubleshooting</li> <li>Experiment with CNI, storage and GitOps tools</li> <li>Maintain a simple but realistic setup</li> </ul>"},{"location":"overview/#high-level-architecture","title":"High-level architecture","text":"<p>The cluster consists of: - one dedicated control plane node - multiple worker nodes - a flat Layer 2 home LAN - static IP addressing or DHCP reservations - a dedicated Pod network</p> <p>All nodes run: - Ubuntu Server - containerd as container runtime - kubeadm-managed Kubernetes components</p>"},{"location":"overview/#design-principles","title":"Design principles","text":"<p>This cluster follows a few key design principles:</p> <ul> <li>Simplicity over complexity</li> <li>Predictability over automation</li> <li>Reproducibility over convenience</li> <li>Documentation-first approach</li> </ul> <p>Each component is installed and configured explicitly to ensure full understanding of what happens under the hood.</p>"},{"location":"overview/#scope-and-limitations","title":"Scope and limitations","text":"<p>This home lab intentionally has the following limitations:</p> <ul> <li>Single control plane (no HA)</li> <li>No external load balancer</li> <li>No cloud provider integration</li> <li>No managed services</li> </ul> <p>These limitations keep the cluster easy to reason about while still allowing meaningful Kubernetes experimentation.</p>"},{"location":"overview/#documentation-structure","title":"Documentation structure","text":"<p>The documentation is organized as follows:</p> <ol> <li>Hardware description reminds the physical foundation</li> <li>Network topology explains physical and logical connectivity</li> <li>OS preparation ensures all nodes are Kubernetes-ready</li> <li>Kubernetes installation describes kubeadm setup</li> <li>CNI configuration focuses on pod networking</li> <li>Validation ensures cluster health and correctness</li> </ol> <p>Each section builds on the previous one and should be followed in order.</p>"},{"location":"validation/","title":"Cluster Validation","text":"<p>This section validates that the Kubernetes cluster is healthy, functional and ready for workloads.</p> <p>The checks below are intentionally simple and reproducible. They focus on core Kubernetes components, networking, and basic scheduling.</p>"},{"location":"validation/#node-status","title":"Node status","text":"<p>Verify that all nodes are registered and ready:</p> <pre><code>kubectl get nodes -o wide\n</code></pre>"},{"location":"validation/#expected","title":"Expected:","text":"<ul> <li>all nodes are in Ready state</li> <li>control plane has the role control-plane</li> <li>worker nodes have no role</li> <li>correct internal IPs are reported</li> </ul>"},{"location":"validation/#system-pods-status","title":"System pods status","text":""},{"location":"validation/#check-core-system-components","title":"Check core system components:","text":"<pre><code>kubectl get pods -n kube-system\n</code></pre>"},{"location":"validation/#expected_1","title":"Expected:","text":"<ul> <li>kube-apiserver: Running</li> <li>kube-controller-manager: Running</li> <li>kube-scheduler: Running</li> <li>etcd: Running</li> <li>calico-node: Running on all nodes</li> <li>calico-kube-controllers: Running</li> </ul> <p>No pods should be in CrashLoopBackOff or Pending.</p>"},{"location":"validation/#component-health","title":"Component health","text":""},{"location":"validation/#verify-control-plane-component-health","title":"Verify control plane component health:","text":"<pre><code>kubectl get componentstatuses\n</code></pre> <p>Expected:</p> <ul> <li>all components report Healthy</li> </ul> <p>Note: This command is deprecated but still useful for quick validation.</p>"},{"location":"validation/#cluster-events","title":"Cluster events","text":"<p>Inspect recent cluster events:</p> <pre><code>kubectl get events -A --sort-by=.metadata.creationTimestamp\n</code></pre>"},{"location":"validation/#expected_2","title":"Expected:","text":"<ul> <li>no recurring errors</li> <li>no certificate or networking failures</li> </ul> <p>Warnings may appear briefly during startup but should not persist.</p>"},{"location":"validation/#dns-resolution","title":"DNS resolution","text":""},{"location":"validation/#validate-coredns-functionality","title":"Validate CoreDNS functionality:","text":"<pre><code>kubectl run dns-test \\\n--image=busybox \\\n--restart=Never \\\n--rm -it -- \\\nnslookup kubernetes.default\n</code></pre>"},{"location":"validation/#expected_3","title":"Expected:","text":"<ul> <li>DNS resolution succeeds</li> <li>service IP is returned</li> </ul>"},{"location":"validation/#pod-to-pod-networking","title":"Pod-to-Pod networking","text":""},{"location":"validation/#deploy-two-test-pods-on-different-nodes","title":"Deploy two test pods on different nodes:","text":"<pre><code>kubectl run pod-a --image=busybox --restart=Never -- sleep 3600\nkubectl run pod-b --image=busybox --restart=Never -- sleep 3600\n</code></pre>"},{"location":"validation/#check-pod-placement-and-ips","title":"Check pod placement and IPs:","text":"<pre><code>kubectl get pods -o wide\n</code></pre>"},{"location":"validation/#verify-connectivity","title":"Verify connectivity:","text":"<pre><code>kubectl exec pod-a -- ping -c 3 &lt;POD-B-IP&gt;\n</code></pre>"},{"location":"validation/#expected_4","title":"Expected:","text":"<ul> <li>ICMP traffic succeeds</li> <li>no packet loss</li> </ul>"},{"location":"validation/#cleanup-test-pods","title":"Cleanup test pods","text":"<pre><code>kubectl delete pod pod-a pod-b\n</code></pre>"},{"location":"validation/#api-server-access","title":"API server access","text":""},{"location":"validation/#verify-api-access-and-permissions","title":"Verify API access and permissions:","text":"<pre><code>kubectl auth can-i get pods --all-namespaces\n</code></pre>"},{"location":"validation/#expected_5","title":"Expected:","text":"<ul> <li>yes</li> </ul>"},{"location":"validation/#summary","title":"Summary","text":""},{"location":"validation/#at-this-stage","title":"At this stage:","text":"<ul> <li>All nodes are Ready</li> <li>Core control plane components are healthy</li> <li>Calico networking is functional</li> <li>DNS resolution works</li> <li>Pod-to-Pod communication is verified</li> </ul> <p>The Kubernetes cluster is fully operational and ready for workloads.</p>"},{"location":"worker-join/","title":"Join Worker Nodes","text":"<p>This section describes how to join worker nodes to the Kubernetes cluster using kubeadm join.</p> <p>At the end of this section: - all worker nodes will be part of the cluster - nodes will be in <code>Ready</code> state - Pod networking will work across nodes</p>"},{"location":"worker-join/#prerequisites","title":"Prerequisites","text":"<p>Before joining worker nodes, ensure that:</p> <ul> <li>Kubernetes control plane is initialized</li> <li>Calico CNI is installed and running</li> <li><code>kubeadm join</code> command is available</li> <li>Worker nodes completed OS Preparation</li> <li>Kubernetes packages are installed on worker nodes</li> </ul> <p>Verify cluster status on the control plane:</p> <pre><code>kubectl get nodes\n</code></pre> <p>Expected output:</p> <ul> <li>control plane node is Ready</li> </ul>"},{"location":"worker-join/#retrieve-the-join-command","title":"Retrieve the join command","text":"<p>On the control plane node, retrieve (or regenerate) the join command:</p> <pre><code>sudo kubeadm token create --print-join-command\n</code></pre>"},{"location":"worker-join/#example-output","title":"Example output:","text":"<pre><code>kubeadm join 192.168.1.53:6443 \\\n--token abcdef.0123456789abcdef \\\n--discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n</code></pre>"},{"location":"worker-join/#this-command-is-unique-and-time-limited","title":"\u26a0\ufe0f This command is unique and time-limited.","text":""},{"location":"worker-join/#join-worker-nodes_1","title":"Join worker nodes","text":""},{"location":"worker-join/#execute-on-each-worker-node","title":"Execute on each worker node","text":"<p>Run the kubeadm join command on each worker node only:</p> <pre><code>sudo kubeadm join 192.168.1.53:6443 \\\n--token abcdef.0123456789abcdef \\\n--discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n</code></pre>"},{"location":"worker-join/#this-command","title":"This command:","text":"<ul> <li>registers the node with the API server</li> <li>installs required certificates</li> <li>starts kubelet on the worker node</li> </ul>"},{"location":"worker-join/#verify-node-registration","title":"Verify node registration","text":"<p>On the control plane, verify node status:</p> <pre><code>kubectl get nodes\n</code></pre> <p>Expected output:</p> <ul> <li>control plane node: Ready</li> <li>worker nodes: Ready</li> </ul>"},{"location":"worker-join/#example","title":"Example:","text":"<pre><code>NAME        STATUS   ROLES           AGE     VERSION\ncp-1        Ready    control-plane   20m     v1.34.x\nworker-1    Ready    &lt;none&gt;           2m     v1.34.x\nworker-2    Ready    &lt;none&gt;           2m     v1.34.x\n</code></pre>"},{"location":"worker-join/#verify-pod-scheduling-across-nodes","title":"Verify Pod scheduling across nodes","text":""},{"location":"worker-join/#deploy-a-test-pod","title":"Deploy a test Pod:","text":"<pre><code>kubectl run nginx-test --image=nginx --restart=Never\n</code></pre>"},{"location":"worker-join/#check-where-the-pod-is-scheduled","title":"Check where the Pod is scheduled:","text":"<pre><code>kubectl get pod nginx-test -o wide\n</code></pre>"},{"location":"worker-join/#expected","title":"Expected:","text":"<ul> <li>Pod is Running</li> <li>Pod is scheduled on a worker node</li> <li>Pod has an IP from the Pod CIDR range</li> </ul>"},{"location":"worker-join/#cleanup-test-pod","title":"Cleanup test Pod","text":"<pre><code>kubectl delete pod nginx-test\n</code></pre>"},{"location":"worker-join/#common-issues","title":"Common issues","text":""},{"location":"worker-join/#node-stays-in-notready","title":"Node stays in NotReady","text":"<p>Check CNI status:</p> <pre><code>kubectl get pods -n kube-system\n</code></pre> <p>Ensure:</p> <ul> <li>calico-node is running on the worker node</li> <li>no CrashLoopBackOff</li> </ul>"},{"location":"worker-join/#join-token-expired","title":"Join token expired","text":""},{"location":"worker-join/#generate-a-new-token","title":"Generate a new token:","text":"<pre><code>sudo kubeadm token create --print-join-command\n</code></pre>"},{"location":"worker-join/#result","title":"Result","text":"<p>At this stage:</p> <ul> <li>all nodes are successfully joined</li> <li>Pod networking works across nodes</li> <li>the Kubernetes cluster is fully operational</li> </ul>"}]}